{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f3f2a4f5-bf20-47d0-8ddc-f6dc9b0b2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6992faa-3c1b-4521-a556-c6fa72a9049d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d7ac550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparmeters\n",
    "batch_size = 32\n",
    "block_size = 23\n",
    "n_embd = 384\n",
    "n_heads = 6\n",
    "n_blocks = 6\n",
    "dropout_ratio = 0.2\n",
    "lr = 3e-4\n",
    "max_iters = 5001\n",
    "eval_interval = 500\n",
    "eval_iters = 200\n",
    "pad_token = 57\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3862cc3-6a16-4800-b94a-024457549e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "EDA\n",
      "--------------------------------------------------------------------------------\n",
      "Vocabulary : \n",
      "['\\n', ' ', '!', '.', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~']\n",
      "\n",
      "Vocab size : 58\n",
      "\n",
      "First ten samples before shuffling : \n",
      "['~Aacharya.', '~Aadanyan.', '~Aadarshan.', '~Aadesh.', '~Aadhavan.', '~Aadhi.', '~Aadhiraiyan.', '~Aadhirayan.', '~Aadhisan.', '~Aadhithan.']\n",
      "\n",
      "First ten samples after shuffling : \n",
      "['!Charithra.', '!Yarakan.', '!Karunkuzhali.', '~Hariesh.', '~Divahar.', '!Racshana.', '!Shanushana.', '!Rithanyaa.', '!Mythura.', '!Shajeena.']\n",
      "\n",
      "Longest input : ~Jeyachandraramanthanan.\t\tLength : 24\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "text = open(\"Dataset/names.txt\").read()\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab) + 1     # 1 refers to pad token\n",
    "print(\"-\"*80)\n",
    "print(\"EDA\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Vocabulary : \\n{vocab}\\n\\nVocab size : {vocab_size}\\n\")\n",
    "\n",
    "data = open(\"Dataset/names.txt\").read().splitlines()\n",
    "print(f\"First ten samples before shuffling : \\n{data[:10]}\\n\")\n",
    "random.seed(13377)\n",
    "random.shuffle(data)\n",
    "print(f\"First ten samples after shuffling : \\n{data[:10]}\\n\")\n",
    "max_ix = 0\n",
    "for ix, name in enumerate(data):\n",
    "    if len(name) > len(data[max_ix]):\n",
    "        max_ix = ix\n",
    "print(f\"Longest input : {data[max_ix]}\\t\\tLength : {len(data[max_ix])}\\n\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "# Convert the names into their bytes\n",
    "for i, name in enumerate(data):\n",
    "    data[i] = name.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77297f53-4cf0-4658-9199-d208848446c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "    for i,name in enumerate(data):\n",
    "        ix = []\n",
    "        for ch in name:\n",
    "            ix.append(stoi[ch])\n",
    "        data[i] = torch.tensor(ix, dtype = torch.long)\n",
    "        \n",
    "decode = lambda ix: ''.join([itos[i] for i in ix])\n",
    "\n",
    "def pad_sequences(data, pad_token, max_length):\n",
    "    for i,name in enumerate(data):\n",
    "        if len(name) != max_length:\n",
    "            pad_tensor = torch.full((max_length - len(name),), pad_token)\n",
    "            data[i] = torch.cat((name, pad_tensor))\n",
    "\n",
    "def split(data):\n",
    "    n = int(0.9*len(data))\n",
    "    xd = [d[:block_size] for d in data]\n",
    "    yd = [d[1:] for d in data]\n",
    "    xtr = torch.stack(xd[:n])\n",
    "    ytr = torch.stack(yd[:n])\n",
    "    xval = torch.stack(xd[n:])\n",
    "    yval = torch.stack(yd[n:])\n",
    "    return xtr, ytr, xval, yval\n",
    "\n",
    "def get_batch(mode):\n",
    "    if mode == \"train\":\n",
    "        x = xtr\n",
    "        y = ytr\n",
    "    else:\n",
    "        x = xval\n",
    "        y = yval\n",
    "    ix = torch.randint(len(x), (batch_size,))\n",
    "    xb = x[ix]\n",
    "    yb = y[ix]\n",
    "    return xb, yb\n",
    "\n",
    "encode(data)\n",
    "pad_sequences(data, pad_token, max_length = 24)\n",
    "xtr, ytr, xval, yval = split(data)\n",
    "print(f\"Train data size : {len(xtr)}\\n\")\n",
    "print(f\"Val data size : {len(xval)}\\n\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "88d8bcdc-2b42-44be-97c8-6c27ccdc2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode():\n",
    "    names_enc = []\n",
    "    for name in names:\n",
    "        names_enc.append(list(map(int, name.encode('utf-8'))))\n",
    "    return names_enc\n",
    "\n",
    "\n",
    "def  get_counts(names_enc_data):\n",
    "    counts = {}\n",
    "    for name in names_enc_data:\n",
    "        for b_pair in zip(name, name[1:]):\n",
    "            counts[b_pair] = counts.get(b_pair, 0) + 1\n",
    "    return counts\n",
    "#print(sorted(((v,k) for k,v in counts.items()), reverse = True))\n",
    "\n",
    "\n",
    "def merge(names_enc_modified, max_pair, ix):\n",
    "    for j, name in enumerate(names_enc_modified):\n",
    "        new_bytes = []\n",
    "        i = 0\n",
    "        while i < len(name):\n",
    "            if i < len(name)-1 and name[i] == max_pair[0] and name[i+1] == max_pair[1]:\n",
    "                new_bytes.append(ix)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_bytes.append(name[i])\n",
    "                i += 1\n",
    "        names_enc_modified[j] = new_bytes\n",
    "    return names_enc_modified\n",
    "\n",
    "\n",
    "def create_merges(names_enc_copy):\n",
    "    merges = {}\n",
    "    for i in range(num_merges):\n",
    "        counts = get_counts(names_enc_copy)\n",
    "        ix = 256 + i\n",
    "        max_pair = max(counts, key = counts.get)\n",
    "        print(f\"merging pair {max_pair} into {ix}\")\n",
    "        names_enc_copy = merge(names_enc_copy, max_pair, ix)\n",
    "        merges[max_pair] = ix\n",
    "    return names_enc_copy, merges\n",
    "\n",
    "\n",
    "def prepend_start_token_and_append_end_token(names_enc_copy):\n",
    "    for i, b_s in enumerate(names_enc_copy):\n",
    "        if i < 18268:\n",
    "            names_enc_copy[i] = torch.tensor([126] + b_s + [46])\n",
    "        else:\n",
    "            names_enc_copy[i] = torch.tensor([33] + b_s + [46])\n",
    "    return names_enc_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cdc43bf8-2d8c-49a7-9dcf-1d1a811e3cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding data...\n",
      "Applying BPE..Creating merges...\n",
      "merging pair (97, 110) into 256\n",
      "merging pair (116, 104) into 257\n",
      "merging pair (115, 104) into 258\n",
      "merging pair (97, 114) into 259\n",
      "merging pair (105, 110) into 260\n",
      "merging pair (97, 257) into 261\n",
      "merging pair (121, 97) into 262\n",
      "merging pair (101, 101) into 263\n",
      "merging pair (105, 257) into 264\n",
      "merging pair (105, 107) into 265\n",
      "merging pair (114, 97) into 266\n",
      "merging pair (104, 97) into 267\n",
      "merging pair (105, 258) into 268\n",
      "merging pair (101, 110) into 269\n",
      "merging pair (97, 118) into 270\n",
      "merging pair (97, 108) into 271\n",
      "merging pair (260, 105) into 272\n",
      "merging pair (97, 109) into 273\n",
      "merging pair (256, 257) into 274\n",
      "merging pair (97, 115) into 275\n",
      "Prepending and appending start and end tokens...\n"
     ]
    }
   ],
   "source": [
    "with open('Dataset/names.txt', 'r') as f:\n",
    "    names = f.read().splitlines()\n",
    "for i, name in enumerate(names):\n",
    "    names[i] = name[1:-1]\n",
    "\n",
    "print(\"Encoding data...\")\n",
    "names_enc = encode()\n",
    "vocab_size = 276\n",
    "num_merges = vocab_size - 256\n",
    "names_enc_copy = copy.deepcopy(names_enc)\n",
    "print(\"Applying BPE..Creating merges...\")\n",
    "names_enc_copy, merges = create_merges(names_enc_copy)\n",
    "print(\"Prepending and appending start and end tokens...\")\n",
    "names_enc_copy = prepend_start_token_and_append_end_token(names_enc_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "82ed8b51-f0b7-43bb-bc1f-332f0d617ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest input : tensor([ 33,  84, 104, 105, 114, 117, 110, 105, 266, 105,  99, 104, 115, 101,\n",
      "        108, 118, 105,  46])\t\tLength : 18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_ix = 0\n",
    "data = names_enc_copy\n",
    "for ix, name in enumerate(data):\n",
    "    if len(name) > len(data[max_ix]):\n",
    "        max_ix = ix\n",
    "print(f\"Longest input : {data[max_ix]}\\t\\tLength : {len(data[max_ix])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6c7890ad-d109-4a59-8b4e-48597fe1c22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aaby'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[18268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a572b9e7-80ca-42ab-8ffd-f26033dbb722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('~'.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e4d75fde-b0f1-4096-9f26-e86c65286f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('!'.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ff043aa2-b542-45dd-a0de-ed2b9f889490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('.'.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
